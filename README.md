# M2U-Net_TGRS
Model-informed Multistage Unsupervised Network for Hyperspectral Image Super-resolution, TGRS. (PyTorch)

[Jiaxin Li æå˜‰é‘«](https://www.researchgate.net/profile/Li-Jiaxin-20), [Ke Zheng éƒ‘ç‚](https://www.researchgate.net/profile/Ke-Zheng-9), [Lianru Gao é«˜è¿å¦‚](https://scholar.google.com/citations?hl=en&user=f6OnhtcAAAAJ), [Li Ni å€ªä¸½](https://orcid.org/0000-0002-9236-026X), [Min Huang é»„æ—»](https://people.ucas.ac.cn/~huangmin), and [Jocelyn Chanussot](https://scholar.google.com/citations?user=6owK2OQAAAAJ&hl=zh-CN&oi=ao), IEEE Transactions on Geoscience and Remote Sensing (TGRS). 


æ–‡ç« å¯åœ¨è¿™é‡Œä¸‹è½½ğŸ–¼ï¸[**PDF**](./Imgs/M2U-Net.pdf)ï¼ŒThe final version can be downloaded in  ğŸ–¼ï¸[**PDF**](./Imgs/M2U-Net.pdf) 


# $\color{red}{æ¬¢è¿æ·»åŠ  æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

## æœ¬äººè¿˜æå‡ºäº†å…¶ä½™å¤šä¸ªå¼€æºçš„é«˜å…‰è°±-å¤šå…‰è°±è¶…åˆ†èåˆä»£ç ï¼Œå¯ç§»æ­¥è‡³[GitHubä¸»é¡µä¸‹è½½](https://github.com/JiaxinLiCAS) 


### æˆ‘æ˜¯æå˜‰é‘«ï¼Œ25å¹´æ¯•ä¸šäºä¸­ç§‘é™¢ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢çš„ç›´åšç”Ÿï¼Œå¯¼å¸ˆé«˜è¿å¦‚ç ”ç©¶å‘˜ ###

2020.09-2025.07 å°±è¯»äºä¸­å›½ç§‘å­¦é™¢ ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢ äº”å¹´åˆ¶ç›´åšç”Ÿ $\color{red}{å¯¼å¸ˆï¼šé«˜è¿å¦‚ç ”ç©¶å‘˜}$ ã€[å¯¼å¸ˆç©ºå¤©é™¢å®˜ç½‘](https://people.ucas.ac.cn/~gaolianru)ï¼Œ[è°·æ­Œå­¦æœ¯ä¸»é¡µ](https://scholar.google.com/citations?user=La-8gLMAAAAJ&hl=zh-CN)ã€‘

2016.09-2020.7 å°±è¯»äºé‡åº†å¤§å­¦ åœŸæœ¨å·¥ç¨‹å­¦é™¢ æµ‹ç»˜å·¥ç¨‹ä¸“ä¸š

From 2020.09 to 2025.07, I am a PhD candidate at the Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China.
My supervisor is [Lianru Gao](https://scholar.google.com/citations?user=La-8gLMAAAAJ&hl=zh-CN)

From 2016.0 to 2020.7, I studied in the school of civil engineering at Chongqing University, Chongqing, China, for a Bachelor of Engineering.

è¿™æ˜¯æˆ‘çš„[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN)å’Œ[ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)ï¼ŒMore information can be found in my [Google Scholar Citations](https://scholar.google.com/citations?user=aSPDpmgAAAAJ&hl=zh-CN) and my [ResearchGate](https://www.researchgate.net/profile/Jiaxin-Li-lijiaxin?ev=hdr_xprf)


# ä»£ç è§£æ ğŸ‘‡ æœ‰åŠ©ä½ è¯»æ‡‚ä»£ç  ä¾¿äºå¤ç°

ğŸ–¼ï¸**é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç è°ƒè¯•ã€æ•°æ®ä»¿çœŸã€è¿è¡Œç»“æœç­‰ï¼Œéšæ—¶æ·»åŠ **
$\color{red}{æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$



<img src="./Imgs/fig1.png" width="666px"/>

**Fig.1.** Overall Pipeline of proposed method, abbreviated as M2U-Net, for the task of unsupervised hyperspectral image super-resolution.

## Directory structure
<img src="./Imgs/fig2.png" width="200px"/>

**Fig.2.** Directory structure. There are three folders and one main.py file in M2U-Net_TGRS-main.

### checkpoints
This folder is used to store the results and a folder named `TGSF12_band260_S1_0.001_3000_3000_S2_0.004_2000_2000_S3_0.004_7000_7000` is given as an example.

- `BlindNet.pth` is the trained parameters of Stage One.

- `estimated_lr_msi.mat` is the estimated LrMSI in Stage One, i.e., K1 and K2.

- `estimated_psf_srf.mat` is the estimated PSF and SRF.

- `gt_lr_msi.mat` is the gt lr_msi.

- `hr_msi.mat` and `lr_hsi.mat`  are simulated results as the input of our method.

- `opt.txt` is the configuration of our method.

- `Out.mat` is the output of our method.

- `Out_fmsi_S2.mat`, `Out_fhsi_S2.mat`,  `and Out_fusion_S2` are the output of Stage Two, i.e., X_s1, X_s2, and X_input.

- `psf_gt.mat` and  `srf_gt.mat` are the GT PSF and SRF.

- `Stage1.txt` is the training accuracy of Stage One.

- `Stage2.txt` is the training accuracy of Stage Two.
  
- `Stage3.txt` is the training accuracy of Stage Three.
  
### data
This folder is used to store the ground true HSI and corresponding spectral response of multispectral imager, aiming to generate the simulated inputs. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

### model
This folder consists of ten .py files, including 
- `__init__.py`

- `config.py`: all the hyper-parameters can be adjusted here.

- `evaluation.py`: to evaluate the metrics.

- `dip.py`: the network in the Stage Three.

- `network_s2.py`: the network used in the Stage Two. 

- `network_s3.py`: the network used in the Stage Three. 

- `read_data.py`: read and simulate data.

- `select.py`: generate X_input from X_s1 and X_s2.

- `spectral_up.py`: the network in the Stage Two.

- `srf_psf_layer.py`: the network in the Stage One.

### main
- `main.py`: main.py

## How to run our code
- Requirements: codes of networks were tested using PyTorch 1.9.0 version (CUDA 11.4) in Python 3.8.10 on Windows system.

- Parameters: all the parameters need fine-tunning can be found in `config.py`.

- Data: put your HSI data and MSI spectral reponse in `./data/M2U-Net/TG` and `./data/M2U-Net/spectral_response`, respectively. The TianGong-1 HSI data and spectral response of WorldView 2 multispectral imager are given as an example here.

- Run: just simply run `main.py` after adjusting the parameters in `config.py`.

- Results: one folder named `TGSF12_band260_S1_0.001_3000_3000_S2_0.004_2000_2000_S3_0.004_7000_7000` will be generated once `main.py` is run and all the results will be stored in the new folder. A folder named `TGSF12_band260_S1_0.001_3000_3000_S2_0.004_2000_2000_S3_0.004_7000_7000` is given as an example here.


## Contact

é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç è°ƒè¯•ã€æ•°æ®ä»¿çœŸã€è¿è¡Œç»“æœç­‰ï¼Œéšæ—¶æ·»åŠ 
$\color{red}{æˆ‘çš„å¾®ä¿¡(WeChat): BatAugï¼Œæ¬¢è¿äº¤æµä¸åˆä½œ}$

If you encounter any bugs while using this code, please do not hesitate to contact us. lijiaxin203@mails.ucas.ac.cn
